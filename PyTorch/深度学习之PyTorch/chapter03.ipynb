{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T01:30:06.941617Z",
     "start_time": "2019-09-05T01:30:06.039002Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T07:34:03.844145Z",
     "start_time": "2019-09-04T07:34:03.836644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is: tensor([[2., 3.],\n",
      "        [4., 8.],\n",
      "        [7., 9.]])\n",
      "a size is: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[2, 3], [4, 8], [7, 9]])\n",
    "print('a is: {}'.format(a))\n",
    "print('a size is: {}'.format(a.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T07:16:19.292625Z",
     "start_time": "2019-09-05T07:16:19.286125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T07:32:59.288447Z",
     "start_time": "2019-09-04T07:32:59.276446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [4, 8],\n",
       "        [7, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.LongTensor([[2, 3], [4, 8], [7, 9]])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T07:36:19.769905Z",
     "start_time": "2019-09-04T07:36:19.764904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.zeros(2, 3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T07:37:22.672393Z",
     "start_time": "2019-09-04T07:37:22.457865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7980, -0.4591],\n",
       "        [-0.5268,  0.6956],\n",
       "        [-0.7297, -0.0186]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.randn((3, 2))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T07:37:57.509316Z",
     "start_time": "2019-09-04T07:37:57.452809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.9798e-01,  1.0000e+02],\n",
       "        [-5.2678e-01,  6.9562e-01],\n",
       "        [-7.2968e-01, -1.8628e-02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0, 1] = 100\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T07:39:14.331072Z",
     "start_time": "2019-09-04T07:39:14.325571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [4, 8],\n",
       "       [7, 9]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_b = b.numpy()\n",
    "numpy_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T07:40:15.064784Z",
     "start_time": "2019-09-04T07:40:15.037280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [4., 8.],\n",
       "        [7., 9.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_b = b.float()\n",
    "f_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T07:42:58.034978Z",
     "start_time": "2019-09-04T07:42:48.229733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3.],\n",
      "        [4., 8.],\n",
      "        [7., 9.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    a_cuda = a.cuda()\n",
    "    print(a_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T07:50:24.173631Z",
     "start_time": "2019-09-04T07:50:24.168130Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:03:04.874728Z",
     "start_time": "2019-09-04T08:03:04.863226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n",
      "tensor([1.])\n",
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([1]), requires_grad=True)\n",
    "w = Variable(torch.Tensor([2]), requires_grad=True)\n",
    "b = Variable(torch.Tensor([3]), requires_grad=True)\n",
    "\n",
    "y = w * x + b\n",
    "\n",
    "y.backward()  # 对所有的需要梯度的变量进行求导，标量求导里面的参数可省略\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:05:56.604034Z",
     "start_time": "2019-09-04T08:05:56.593533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.8765, -0.5525, -3.7880], grad_fn=<MulBackward0>)\n",
      "tensor([ 2.0000,  0.2000, 40.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "print(y)\n",
    "\n",
    "y.backward(torch.FloatTensor([1, 0.1, 20])) # 原本的梯度需分别乘上对应的值\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:01:34.038693Z",
     "start_time": "2019-09-04T08:01:34.031692Z"
    }
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:31:20.771579Z",
     "start_time": "2019-09-04T08:31:20.768079Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:23:32.870163Z",
     "start_time": "2019-09-04T08:23:32.863162Z"
    }
   },
   "outputs": [],
   "source": [
    "ImageFolder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:50:11.228629Z",
     "start_time": "2019-09-04T08:50:11.222128Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)# submodule: Conv2d\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T09:09:43.630005Z",
     "start_time": "2019-09-04T09:09:43.585999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\deeplearning\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "torch.save(model, './model.pth')\n",
    "torch.save(model.state_dict(), './model_state.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一元线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T01:41:43.779359Z",
     "start_time": "2019-09-05T01:41:43.776359Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T01:31:11.060259Z",
     "start_time": "2019-09-05T01:31:11.054258Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168],\n",
    "                    [9.779], [6.182], [7.59], [2.167], \n",
    "                    [7.042], [10.791], [5.313], [7.997],\n",
    "                    [3.1]], dtype=np.float32)\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], \n",
    "                    [1.573], [3.366], [2.596], [2.53], [1.221], \n",
    "                    [2.827], [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T02:09:44.363266Z",
     "start_time": "2019-09-05T02:09:44.111734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x647c70b8>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train, y_train, 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T01:32:08.916106Z",
     "start_time": "2019-09-05T01:32:08.838096Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train)\n",
    "y_train = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T01:37:30.998260Z",
     "start_time": "2019-09-05T01:37:30.992759Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1) # 输入1维，输出1维\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:38:38.032766Z",
     "start_time": "2019-09-05T08:38:35.021383Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9798, device='cuda:0')\n",
      "Epoch [20/1000], loss: 0.979787\n",
      "tensor(0.3648, device='cuda:0')\n",
      "Epoch [40/1000], loss: 0.364849\n",
      "tensor(0.3465, device='cuda:0')\n",
      "Epoch [60/1000], loss: 0.346506\n",
      "tensor(0.3443, device='cuda:0')\n",
      "Epoch [80/1000], loss: 0.344251\n",
      "tensor(0.3424, device='cuda:0')\n",
      "Epoch [100/1000], loss: 0.342447\n",
      "tensor(0.3407, device='cuda:0')\n",
      "Epoch [120/1000], loss: 0.340673\n",
      "tensor(0.3389, device='cuda:0')\n",
      "Epoch [140/1000], loss: 0.338917\n",
      "tensor(0.3372, device='cuda:0')\n",
      "Epoch [160/1000], loss: 0.337180\n",
      "tensor(0.3355, device='cuda:0')\n",
      "Epoch [180/1000], loss: 0.335460\n",
      "tensor(0.3338, device='cuda:0')\n",
      "Epoch [200/1000], loss: 0.333757\n",
      "tensor(0.3321, device='cuda:0')\n",
      "Epoch [220/1000], loss: 0.332072\n",
      "tensor(0.3304, device='cuda:0')\n",
      "Epoch [240/1000], loss: 0.330405\n",
      "tensor(0.3288, device='cuda:0')\n",
      "Epoch [260/1000], loss: 0.328754\n",
      "tensor(0.3271, device='cuda:0')\n",
      "Epoch [280/1000], loss: 0.327120\n",
      "tensor(0.3255, device='cuda:0')\n",
      "Epoch [300/1000], loss: 0.325503\n",
      "tensor(0.3239, device='cuda:0')\n",
      "Epoch [320/1000], loss: 0.323903\n",
      "tensor(0.3223, device='cuda:0')\n",
      "Epoch [340/1000], loss: 0.322318\n",
      "tensor(0.3208, device='cuda:0')\n",
      "Epoch [360/1000], loss: 0.320750\n",
      "tensor(0.3192, device='cuda:0')\n",
      "Epoch [380/1000], loss: 0.319198\n",
      "tensor(0.3177, device='cuda:0')\n",
      "Epoch [400/1000], loss: 0.317662\n",
      "tensor(0.3161, device='cuda:0')\n",
      "Epoch [420/1000], loss: 0.316142\n",
      "tensor(0.3146, device='cuda:0')\n",
      "Epoch [440/1000], loss: 0.314637\n",
      "tensor(0.3131, device='cuda:0')\n",
      "Epoch [460/1000], loss: 0.313147\n",
      "tensor(0.3117, device='cuda:0')\n",
      "Epoch [480/1000], loss: 0.311673\n",
      "tensor(0.3102, device='cuda:0')\n",
      "Epoch [500/1000], loss: 0.310214\n",
      "tensor(0.3088, device='cuda:0')\n",
      "Epoch [520/1000], loss: 0.308770\n",
      "tensor(0.3073, device='cuda:0')\n",
      "Epoch [540/1000], loss: 0.307340\n",
      "tensor(0.3059, device='cuda:0')\n",
      "Epoch [560/1000], loss: 0.305925\n",
      "tensor(0.3045, device='cuda:0')\n",
      "Epoch [580/1000], loss: 0.304525\n",
      "tensor(0.3031, device='cuda:0')\n",
      "Epoch [600/1000], loss: 0.303139\n",
      "tensor(0.3018, device='cuda:0')\n",
      "Epoch [620/1000], loss: 0.301767\n",
      "tensor(0.3004, device='cuda:0')\n",
      "Epoch [640/1000], loss: 0.300409\n",
      "tensor(0.2991, device='cuda:0')\n",
      "Epoch [660/1000], loss: 0.299065\n",
      "tensor(0.2977, device='cuda:0')\n",
      "Epoch [680/1000], loss: 0.297734\n",
      "tensor(0.2964, device='cuda:0')\n",
      "Epoch [700/1000], loss: 0.296418\n",
      "tensor(0.2951, device='cuda:0')\n",
      "Epoch [720/1000], loss: 0.295114\n",
      "tensor(0.2938, device='cuda:0')\n",
      "Epoch [740/1000], loss: 0.293824\n",
      "tensor(0.2925, device='cuda:0')\n",
      "Epoch [760/1000], loss: 0.292548\n",
      "tensor(0.2913, device='cuda:0')\n",
      "Epoch [780/1000], loss: 0.291284\n",
      "tensor(0.2900, device='cuda:0')\n",
      "Epoch [800/1000], loss: 0.290033\n",
      "tensor(0.2888, device='cuda:0')\n",
      "Epoch [820/1000], loss: 0.288795\n",
      "tensor(0.2876, device='cuda:0')\n",
      "Epoch [840/1000], loss: 0.287570\n",
      "tensor(0.2864, device='cuda:0')\n",
      "Epoch [860/1000], loss: 0.286357\n",
      "tensor(0.2852, device='cuda:0')\n",
      "Epoch [880/1000], loss: 0.285156\n",
      "tensor(0.2840, device='cuda:0')\n",
      "Epoch [900/1000], loss: 0.283968\n",
      "tensor(0.2828, device='cuda:0')\n",
      "Epoch [920/1000], loss: 0.282792\n",
      "tensor(0.2816, device='cuda:0')\n",
      "Epoch [940/1000], loss: 0.281628\n",
      "tensor(0.2805, device='cuda:0')\n",
      "Epoch [960/1000], loss: 0.280476\n",
      "tensor(0.2793, device='cuda:0')\n",
      "Epoch [980/1000], loss: 0.279336\n",
      "tensor(0.2782, device='cuda:0')\n",
      "Epoch [1000/1000], loss: 0.278207\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = LinearRegression().cuda()\n",
    "else:\n",
    "    model = LinearRegression()\n",
    "\n",
    "# 使用均方误差作为优化函数，使用梯度下降进行优化\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(x_train).cuda()\n",
    "        target = Variable(y_train).cuda()\n",
    "    else:\n",
    "        inputs = Variable(x_train)\n",
    "        target = Variable(y_train)\n",
    "        \n",
    "    # forward\n",
    "    out = model(inputs) # 得到网络前向传播的结果\n",
    "    loss = criterion(out, target) # 得到损失函数\n",
    "    # backward：归零梯度、做反向传播和更新参数\n",
    "    # 每次做反向传播之前都要归零梯度，不然梯度会累加在一起，造成结果不收敛\n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(loss.data)\n",
    "        print('Epoch [{}/{}], loss: {:.6f}'.format(epoch+1, num_epochs, loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:38:44.759620Z",
     "start_time": "2019-09-05T08:38:44.552094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x785ab5f8>]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 因为有一些操作，如Dropout和BatchNormalization在训练和测试的时候是不一样的\n",
    "model.eval() # 将模型变成测试模式\n",
    "# 将测试数据放入网络做前向传播得到结果\n",
    "predict = model(Variable(x_train).cuda())\n",
    "predict = predict.data.cpu().numpy()\n",
    "plt.plot(x_train.numpy(), y_train.numpy(), 'ro', label='Original data')\n",
    "plt.plot(x_train.numpy(), predict, label='Fitting Line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多项式回归\n",
    "要拟合方程：\n",
    "$$y=0.9+0.5x+3x^2+2.4x^3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T03:31:26.769793Z",
     "start_time": "2019-09-05T03:31:20.017435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], loss is 63.224606\n",
      "Epoch [2/1000], loss is 329.315826\n",
      "Epoch [3/1000], loss is 74.356514\n",
      "Epoch [4/1000], loss is 16.382524\n",
      "Epoch [5/1000], loss is 23.492283\n",
      "Epoch [6/1000], loss is 34.487183\n",
      "Epoch [7/1000], loss is 22.017040\n",
      "Epoch [8/1000], loss is 19.659861\n",
      "Epoch [9/1000], loss is 317.705627\n",
      "Epoch [10/1000], loss is 99.665833\n",
      "Epoch [11/1000], loss is 86.249809\n",
      "Epoch [12/1000], loss is 26.801586\n",
      "Epoch [13/1000], loss is 13.603171\n",
      "Epoch [14/1000], loss is 104.095947\n",
      "Epoch [15/1000], loss is 52.266541\n",
      "Epoch [16/1000], loss is 68.510231\n",
      "Epoch [17/1000], loss is 137.791687\n",
      "Epoch [18/1000], loss is 94.888817\n",
      "Epoch [19/1000], loss is 8.087149\n",
      "Epoch [20/1000], loss is 68.848000\n",
      "Epoch [21/1000], loss is 27.250633\n",
      "Epoch [22/1000], loss is 52.934765\n",
      "Epoch [23/1000], loss is 92.486443\n",
      "Epoch [24/1000], loss is 99.169388\n",
      "Epoch [25/1000], loss is 54.018593\n",
      "Epoch [26/1000], loss is 43.083260\n",
      "Epoch [27/1000], loss is 57.125820\n",
      "Epoch [28/1000], loss is 26.748274\n",
      "Epoch [29/1000], loss is 17.558388\n",
      "Epoch [30/1000], loss is 47.575722\n",
      "Epoch [31/1000], loss is 22.264954\n",
      "Epoch [32/1000], loss is 20.664547\n",
      "Epoch [33/1000], loss is 25.708973\n",
      "Epoch [34/1000], loss is 21.583662\n",
      "Epoch [35/1000], loss is 8.948771\n",
      "Epoch [36/1000], loss is 68.023315\n",
      "Epoch [37/1000], loss is 85.891113\n",
      "Epoch [38/1000], loss is 9.374353\n",
      "Epoch [39/1000], loss is 28.988689\n",
      "Epoch [40/1000], loss is 29.415543\n",
      "Epoch [41/1000], loss is 8.349035\n",
      "Epoch [42/1000], loss is 14.053583\n",
      "Epoch [43/1000], loss is 5.619810\n",
      "Epoch [44/1000], loss is 20.352295\n",
      "Epoch [45/1000], loss is 7.133629\n",
      "Epoch [46/1000], loss is 7.313571\n",
      "Epoch [47/1000], loss is 18.198036\n",
      "Epoch [48/1000], loss is 10.377436\n",
      "Epoch [49/1000], loss is 28.340050\n",
      "Epoch [50/1000], loss is 24.471390\n",
      "Epoch [51/1000], loss is 13.770575\n",
      "Epoch [52/1000], loss is 42.245087\n",
      "Epoch [53/1000], loss is 28.767830\n",
      "Epoch [54/1000], loss is 16.099052\n",
      "Epoch [55/1000], loss is 26.617926\n",
      "Epoch [56/1000], loss is 17.970287\n",
      "Epoch [57/1000], loss is 9.216566\n",
      "Epoch [58/1000], loss is 12.120790\n",
      "Epoch [59/1000], loss is 16.623135\n",
      "Epoch [60/1000], loss is 20.489285\n",
      "Epoch [61/1000], loss is 6.212613\n",
      "Epoch [62/1000], loss is 14.869363\n",
      "Epoch [63/1000], loss is 27.680099\n",
      "Epoch [64/1000], loss is 11.168653\n",
      "Epoch [65/1000], loss is 12.951176\n",
      "Epoch [66/1000], loss is 10.879645\n",
      "Epoch [67/1000], loss is 111.953934\n",
      "Epoch [68/1000], loss is 16.387737\n",
      "Epoch [69/1000], loss is 18.957682\n",
      "Epoch [70/1000], loss is 12.137594\n",
      "Epoch [71/1000], loss is 7.062840\n",
      "Epoch [72/1000], loss is 10.425329\n",
      "Epoch [73/1000], loss is 26.730114\n",
      "Epoch [74/1000], loss is 20.058159\n",
      "Epoch [75/1000], loss is 8.011697\n",
      "Epoch [76/1000], loss is 4.345951\n",
      "Epoch [77/1000], loss is 18.170855\n",
      "Epoch [78/1000], loss is 8.411118\n",
      "Epoch [79/1000], loss is 13.711472\n",
      "Epoch [80/1000], loss is 13.291862\n",
      "Epoch [81/1000], loss is 22.690865\n",
      "Epoch [82/1000], loss is 6.431776\n",
      "Epoch [83/1000], loss is 14.433247\n",
      "Epoch [84/1000], loss is 8.616602\n",
      "Epoch [85/1000], loss is 6.980820\n",
      "Epoch [86/1000], loss is 7.688818\n",
      "Epoch [87/1000], loss is 12.549536\n",
      "Epoch [88/1000], loss is 9.013425\n",
      "Epoch [89/1000], loss is 4.690794\n",
      "Epoch [90/1000], loss is 9.303780\n",
      "Epoch [91/1000], loss is 5.389143\n",
      "Epoch [92/1000], loss is 9.846096\n",
      "Epoch [93/1000], loss is 10.205618\n",
      "Epoch [94/1000], loss is 8.699264\n",
      "Epoch [95/1000], loss is 14.215757\n",
      "Epoch [96/1000], loss is 8.817525\n",
      "Epoch [97/1000], loss is 13.396349\n",
      "Epoch [98/1000], loss is 4.646986\n",
      "Epoch [99/1000], loss is 4.093242\n",
      "Epoch [100/1000], loss is 6.247394\n",
      "Epoch [101/1000], loss is 19.699734\n",
      "Epoch [102/1000], loss is 15.445243\n",
      "Epoch [103/1000], loss is 14.182935\n",
      "Epoch [104/1000], loss is 10.988373\n",
      "Epoch [105/1000], loss is 12.391867\n",
      "Epoch [106/1000], loss is 13.432920\n",
      "Epoch [107/1000], loss is 4.295188\n",
      "Epoch [108/1000], loss is 6.074369\n",
      "Epoch [109/1000], loss is 4.155910\n",
      "Epoch [110/1000], loss is 5.001525\n",
      "Epoch [111/1000], loss is 7.697752\n",
      "Epoch [112/1000], loss is 3.079071\n",
      "Epoch [113/1000], loss is 14.106192\n",
      "Epoch [114/1000], loss is 3.180401\n",
      "Epoch [115/1000], loss is 5.909230\n",
      "Epoch [116/1000], loss is 8.864508\n",
      "Epoch [117/1000], loss is 2.912938\n",
      "Epoch [118/1000], loss is 8.886683\n",
      "Epoch [119/1000], loss is 7.940982\n",
      "Epoch [120/1000], loss is 6.702977\n",
      "Epoch [121/1000], loss is 5.793108\n",
      "Epoch [122/1000], loss is 7.149605\n",
      "Epoch [123/1000], loss is 11.706169\n",
      "Epoch [124/1000], loss is 3.619518\n",
      "Epoch [125/1000], loss is 6.686639\n",
      "Epoch [126/1000], loss is 8.718517\n",
      "Epoch [127/1000], loss is 3.969534\n",
      "Epoch [128/1000], loss is 7.475869\n",
      "Epoch [129/1000], loss is 3.131342\n",
      "Epoch [130/1000], loss is 5.873147\n",
      "Epoch [131/1000], loss is 4.651498\n",
      "Epoch [132/1000], loss is 7.002849\n",
      "Epoch [133/1000], loss is 4.998413\n",
      "Epoch [134/1000], loss is 5.405918\n",
      "Epoch [135/1000], loss is 2.984213\n",
      "Epoch [136/1000], loss is 4.484004\n",
      "Epoch [137/1000], loss is 5.948805\n",
      "Epoch [138/1000], loss is 5.051860\n",
      "Epoch [139/1000], loss is 3.839983\n",
      "Epoch [140/1000], loss is 3.586357\n",
      "Epoch [141/1000], loss is 3.890215\n",
      "Epoch [142/1000], loss is 7.869212\n",
      "Epoch [143/1000], loss is 6.258024\n",
      "Epoch [144/1000], loss is 3.644588\n",
      "Epoch [145/1000], loss is 3.788451\n",
      "Epoch [146/1000], loss is 1.549424\n",
      "Epoch [147/1000], loss is 3.289852\n",
      "Epoch [148/1000], loss is 3.244192\n",
      "Epoch [149/1000], loss is 4.929492\n",
      "Epoch [150/1000], loss is 5.289368\n",
      "Epoch [151/1000], loss is 2.973160\n",
      "Epoch [152/1000], loss is 5.438227\n",
      "Epoch [153/1000], loss is 8.406643\n",
      "Epoch [154/1000], loss is 3.670663\n",
      "Epoch [155/1000], loss is 2.946363\n",
      "Epoch [156/1000], loss is 4.537876\n",
      "Epoch [157/1000], loss is 3.135699\n",
      "Epoch [158/1000], loss is 3.591346\n",
      "Epoch [159/1000], loss is 2.817339\n",
      "Epoch [160/1000], loss is 5.599522\n",
      "Epoch [161/1000], loss is 2.057923\n",
      "Epoch [162/1000], loss is 4.537023\n",
      "Epoch [163/1000], loss is 4.044760\n",
      "Epoch [164/1000], loss is 2.297012\n",
      "Epoch [165/1000], loss is 2.811432\n",
      "Epoch [166/1000], loss is 1.724779\n",
      "Epoch [167/1000], loss is 4.448313\n",
      "Epoch [168/1000], loss is 5.757042\n",
      "Epoch [169/1000], loss is 5.152149\n",
      "Epoch [170/1000], loss is 3.257161\n",
      "Epoch [171/1000], loss is 1.880212\n",
      "Epoch [172/1000], loss is 2.312360\n",
      "Epoch [173/1000], loss is 3.486102\n",
      "Epoch [174/1000], loss is 3.956205\n",
      "Epoch [175/1000], loss is 3.035501\n",
      "Epoch [176/1000], loss is 3.208203\n",
      "Epoch [177/1000], loss is 2.194418\n",
      "Epoch [178/1000], loss is 2.931766\n",
      "Epoch [179/1000], loss is 1.972570\n",
      "Epoch [180/1000], loss is 3.176348\n",
      "Epoch [181/1000], loss is 3.330443\n",
      "Epoch [182/1000], loss is 2.610820\n",
      "Epoch [183/1000], loss is 2.195152\n",
      "Epoch [184/1000], loss is 4.347718\n",
      "Epoch [185/1000], loss is 2.854067\n",
      "Epoch [186/1000], loss is 3.927043\n",
      "Epoch [187/1000], loss is 4.635510\n",
      "Epoch [188/1000], loss is 2.977109\n",
      "Epoch [189/1000], loss is 2.764881\n",
      "Epoch [190/1000], loss is 2.843855\n",
      "Epoch [191/1000], loss is 2.489624\n",
      "Epoch [192/1000], loss is 4.101924\n",
      "Epoch [193/1000], loss is 1.118961\n",
      "Epoch [194/1000], loss is 1.148319\n",
      "Epoch [195/1000], loss is 2.783620\n",
      "Epoch [196/1000], loss is 3.791783\n",
      "Epoch [197/1000], loss is 1.801742\n",
      "Epoch [198/1000], loss is 2.138424\n",
      "Epoch [199/1000], loss is 1.971564\n",
      "Epoch [200/1000], loss is 3.180693\n",
      "Epoch [201/1000], loss is 1.607490\n",
      "Epoch [202/1000], loss is 1.993026\n",
      "Epoch [203/1000], loss is 1.696953\n",
      "Epoch [204/1000], loss is 1.629127\n",
      "Epoch [205/1000], loss is 1.607617\n",
      "Epoch [206/1000], loss is 1.258683\n",
      "Epoch [207/1000], loss is 1.874903\n",
      "Epoch [208/1000], loss is 1.859514\n",
      "Epoch [209/1000], loss is 1.746919\n",
      "Epoch [210/1000], loss is 1.750500\n",
      "Epoch [211/1000], loss is 2.385007\n",
      "Epoch [212/1000], loss is 1.689773\n",
      "Epoch [213/1000], loss is 1.537627\n",
      "Epoch [214/1000], loss is 1.647087\n",
      "Epoch [215/1000], loss is 0.809374\n",
      "Epoch [216/1000], loss is 1.912931\n",
      "Epoch [217/1000], loss is 2.130362\n",
      "Epoch [218/1000], loss is 0.892428\n",
      "Epoch [219/1000], loss is 1.061502\n",
      "Epoch [220/1000], loss is 3.214129\n",
      "Epoch [221/1000], loss is 1.433934\n",
      "Epoch [222/1000], loss is 1.575100\n",
      "Epoch [223/1000], loss is 1.087346\n",
      "Epoch [224/1000], loss is 0.942730\n",
      "Epoch [225/1000], loss is 1.369895\n",
      "Epoch [226/1000], loss is 0.855259\n",
      "Epoch [227/1000], loss is 1.450803\n",
      "Epoch [228/1000], loss is 1.310290\n",
      "Epoch [229/1000], loss is 1.288096\n",
      "Epoch [230/1000], loss is 1.137184\n",
      "Epoch [231/1000], loss is 0.829261\n",
      "Epoch [232/1000], loss is 2.022361\n",
      "Epoch [233/1000], loss is 1.268462\n",
      "Epoch [234/1000], loss is 1.245485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [235/1000], loss is 2.099534\n",
      "Epoch [236/1000], loss is 0.998499\n",
      "Epoch [237/1000], loss is 1.154873\n",
      "Epoch [238/1000], loss is 1.171959\n",
      "Epoch [239/1000], loss is 0.874997\n",
      "Epoch [240/1000], loss is 0.745850\n",
      "Epoch [241/1000], loss is 0.992144\n",
      "Epoch [242/1000], loss is 0.594074\n",
      "Epoch [243/1000], loss is 0.729448\n",
      "Epoch [244/1000], loss is 1.032258\n",
      "Epoch [245/1000], loss is 0.588522\n",
      "Epoch [246/1000], loss is 3.141600\n",
      "Epoch [247/1000], loss is 4.811688\n",
      "Epoch [248/1000], loss is 0.838670\n",
      "Epoch [249/1000], loss is 1.313286\n",
      "Epoch [250/1000], loss is 1.097589\n",
      "Epoch [251/1000], loss is 0.826441\n",
      "Epoch [252/1000], loss is 1.465272\n",
      "Epoch [253/1000], loss is 0.729620\n",
      "Epoch [254/1000], loss is 1.336198\n",
      "Epoch [255/1000], loss is 1.657773\n",
      "Epoch [256/1000], loss is 0.985265\n",
      "Epoch [257/1000], loss is 1.133662\n",
      "Epoch [258/1000], loss is 0.666003\n",
      "Epoch [259/1000], loss is 1.516788\n",
      "Epoch [260/1000], loss is 0.859536\n",
      "Epoch [261/1000], loss is 0.613734\n",
      "Epoch [262/1000], loss is 0.980975\n",
      "Epoch [263/1000], loss is 0.448634\n",
      "Epoch [264/1000], loss is 2.301261\n",
      "Epoch [265/1000], loss is 0.792659\n",
      "Epoch [266/1000], loss is 0.892854\n",
      "Epoch [267/1000], loss is 2.789536\n",
      "Epoch [268/1000], loss is 2.115059\n",
      "Epoch [269/1000], loss is 0.543328\n",
      "Epoch [270/1000], loss is 0.619868\n",
      "Epoch [271/1000], loss is 1.037535\n",
      "Epoch [272/1000], loss is 0.958749\n",
      "Epoch [273/1000], loss is 0.728518\n",
      "Epoch [274/1000], loss is 0.798423\n",
      "Epoch [275/1000], loss is 0.855043\n",
      "Epoch [276/1000], loss is 0.725991\n",
      "Epoch [277/1000], loss is 0.432825\n",
      "Epoch [278/1000], loss is 0.532812\n",
      "Epoch [279/1000], loss is 0.516672\n",
      "Epoch [280/1000], loss is 0.519515\n",
      "Epoch [281/1000], loss is 0.911857\n",
      "Epoch [282/1000], loss is 0.945047\n",
      "Epoch [283/1000], loss is 1.217175\n",
      "Epoch [284/1000], loss is 0.768349\n",
      "Epoch [285/1000], loss is 0.517277\n",
      "Epoch [286/1000], loss is 0.683620\n",
      "Epoch [287/1000], loss is 0.578315\n",
      "Epoch [288/1000], loss is 1.049690\n",
      "Epoch [289/1000], loss is 0.733884\n",
      "Epoch [290/1000], loss is 0.514089\n",
      "Epoch [291/1000], loss is 0.553601\n",
      "Epoch [292/1000], loss is 0.429931\n",
      "Epoch [293/1000], loss is 0.470927\n",
      "Epoch [294/1000], loss is 0.397944\n",
      "Epoch [295/1000], loss is 0.944249\n",
      "Epoch [296/1000], loss is 0.529598\n",
      "Epoch [297/1000], loss is 0.741727\n",
      "Epoch [298/1000], loss is 0.625803\n",
      "Epoch [299/1000], loss is 0.437655\n",
      "Epoch [300/1000], loss is 0.346733\n",
      "Epoch [301/1000], loss is 0.465177\n",
      "Epoch [302/1000], loss is 0.610018\n",
      "Epoch [303/1000], loss is 1.278998\n",
      "Epoch [304/1000], loss is 0.349598\n",
      "Epoch [305/1000], loss is 0.394434\n",
      "Epoch [306/1000], loss is 0.324216\n",
      "Epoch [307/1000], loss is 0.642454\n",
      "Epoch [308/1000], loss is 0.361304\n",
      "Epoch [309/1000], loss is 0.543061\n",
      "Epoch [310/1000], loss is 0.900645\n",
      "Epoch [311/1000], loss is 0.373100\n",
      "Epoch [312/1000], loss is 0.541720\n",
      "Epoch [313/1000], loss is 0.507534\n",
      "Epoch [314/1000], loss is 0.400002\n",
      "Epoch [315/1000], loss is 0.290563\n",
      "Epoch [316/1000], loss is 0.563118\n",
      "Epoch [317/1000], loss is 0.320032\n",
      "Epoch [318/1000], loss is 0.278583\n",
      "Epoch [319/1000], loss is 0.445161\n",
      "Epoch [320/1000], loss is 0.423922\n",
      "Epoch [321/1000], loss is 0.476123\n",
      "Epoch [322/1000], loss is 0.609730\n",
      "Epoch [323/1000], loss is 0.349474\n",
      "Epoch [324/1000], loss is 0.247209\n",
      "Epoch [325/1000], loss is 0.454187\n",
      "Epoch [326/1000], loss is 0.274224\n",
      "Epoch [327/1000], loss is 0.287394\n",
      "Epoch [328/1000], loss is 0.411982\n",
      "Epoch [329/1000], loss is 0.344107\n",
      "Epoch [330/1000], loss is 0.346777\n",
      "Epoch [331/1000], loss is 0.364497\n",
      "Epoch [332/1000], loss is 0.432074\n",
      "Epoch [333/1000], loss is 0.419359\n",
      "Epoch [334/1000], loss is 0.283315\n",
      "Epoch [335/1000], loss is 0.337319\n",
      "Epoch [336/1000], loss is 0.354742\n",
      "Epoch [337/1000], loss is 0.195204\n",
      "Epoch [338/1000], loss is 0.348806\n",
      "Epoch [339/1000], loss is 0.322059\n",
      "Epoch [340/1000], loss is 0.322313\n",
      "Epoch [341/1000], loss is 0.213341\n",
      "Epoch [342/1000], loss is 0.277962\n",
      "Epoch [343/1000], loss is 0.508164\n",
      "Epoch [344/1000], loss is 0.207008\n",
      "Epoch [345/1000], loss is 0.355135\n",
      "Epoch [346/1000], loss is 0.285225\n",
      "Epoch [347/1000], loss is 0.388873\n",
      "Epoch [348/1000], loss is 0.260126\n",
      "Epoch [349/1000], loss is 0.258878\n",
      "Epoch [350/1000], loss is 0.444330\n",
      "Epoch [351/1000], loss is 0.194160\n",
      "Epoch [352/1000], loss is 0.246567\n",
      "Epoch [353/1000], loss is 0.257625\n",
      "Epoch [354/1000], loss is 0.442871\n",
      "Epoch [355/1000], loss is 0.302368\n",
      "Epoch [356/1000], loss is 0.185240\n",
      "Epoch [357/1000], loss is 0.308286\n",
      "Epoch [358/1000], loss is 0.236745\n",
      "Epoch [359/1000], loss is 0.248383\n",
      "Epoch [360/1000], loss is 0.267169\n",
      "Epoch [361/1000], loss is 0.188756\n",
      "Epoch [362/1000], loss is 0.184619\n",
      "Epoch [363/1000], loss is 0.316281\n",
      "Epoch [364/1000], loss is 0.192972\n",
      "Epoch [365/1000], loss is 0.236970\n",
      "Epoch [366/1000], loss is 0.192164\n",
      "Epoch [367/1000], loss is 0.295544\n",
      "Epoch [368/1000], loss is 0.224295\n",
      "Epoch [369/1000], loss is 0.157900\n",
      "Epoch [370/1000], loss is 0.234376\n",
      "Epoch [371/1000], loss is 0.203402\n",
      "Epoch [372/1000], loss is 0.236494\n",
      "Epoch [373/1000], loss is 0.149778\n",
      "Epoch [374/1000], loss is 0.147079\n",
      "Epoch [375/1000], loss is 0.198898\n",
      "Epoch [376/1000], loss is 0.147591\n",
      "Epoch [377/1000], loss is 0.210684\n",
      "Epoch [378/1000], loss is 0.247587\n",
      "Epoch [379/1000], loss is 0.125631\n",
      "Epoch [380/1000], loss is 0.197909\n",
      "Epoch [381/1000], loss is 0.156614\n",
      "Epoch [382/1000], loss is 0.206680\n",
      "Epoch [383/1000], loss is 0.193134\n",
      "Epoch [384/1000], loss is 0.220353\n",
      "Epoch [385/1000], loss is 0.238681\n",
      "Epoch [386/1000], loss is 0.152089\n",
      "Epoch [387/1000], loss is 0.138830\n",
      "Epoch [388/1000], loss is 0.187212\n",
      "Epoch [389/1000], loss is 0.151776\n",
      "Epoch [390/1000], loss is 0.162428\n",
      "Epoch [391/1000], loss is 0.703208\n",
      "Epoch [392/1000], loss is 0.174412\n",
      "Epoch [393/1000], loss is 0.205896\n",
      "Epoch [394/1000], loss is 0.166783\n",
      "Epoch [395/1000], loss is 0.169423\n",
      "Epoch [396/1000], loss is 0.164256\n",
      "Epoch [397/1000], loss is 0.143965\n",
      "Epoch [398/1000], loss is 0.165712\n",
      "Epoch [399/1000], loss is 0.682793\n",
      "Epoch [400/1000], loss is 0.121115\n",
      "Epoch [401/1000], loss is 0.347920\n",
      "Epoch [402/1000], loss is 0.192633\n",
      "Epoch [403/1000], loss is 0.149293\n",
      "Epoch [404/1000], loss is 0.154817\n",
      "Epoch [405/1000], loss is 0.155546\n",
      "Epoch [406/1000], loss is 0.221446\n",
      "Epoch [407/1000], loss is 0.205761\n",
      "Epoch [408/1000], loss is 0.152656\n",
      "Epoch [409/1000], loss is 0.126035\n",
      "Epoch [410/1000], loss is 0.132170\n",
      "Epoch [411/1000], loss is 0.133478\n",
      "Epoch [412/1000], loss is 0.090413\n",
      "Epoch [413/1000], loss is 0.133908\n",
      "Epoch [414/1000], loss is 0.123241\n",
      "Epoch [415/1000], loss is 0.145696\n",
      "Epoch [416/1000], loss is 0.143445\n",
      "Epoch [417/1000], loss is 0.128965\n",
      "Epoch [418/1000], loss is 0.145859\n",
      "Epoch [419/1000], loss is 0.148434\n",
      "Epoch [420/1000], loss is 0.121503\n",
      "Epoch [421/1000], loss is 0.128738\n",
      "Epoch [422/1000], loss is 0.151790\n",
      "Epoch [423/1000], loss is 0.151835\n",
      "Epoch [424/1000], loss is 0.089383\n",
      "Epoch [425/1000], loss is 0.184622\n",
      "Epoch [426/1000], loss is 0.132067\n",
      "Epoch [427/1000], loss is 0.118399\n",
      "Epoch [428/1000], loss is 0.153593\n",
      "Epoch [429/1000], loss is 0.078828\n",
      "Epoch [430/1000], loss is 0.115308\n",
      "Epoch [431/1000], loss is 0.134512\n",
      "Epoch [432/1000], loss is 0.074101\n",
      "Epoch [433/1000], loss is 0.105513\n",
      "Epoch [434/1000], loss is 0.092204\n",
      "Epoch [435/1000], loss is 0.146258\n",
      "Epoch [436/1000], loss is 0.129244\n",
      "Epoch [437/1000], loss is 0.120843\n",
      "Epoch [438/1000], loss is 0.125036\n",
      "Epoch [439/1000], loss is 0.105230\n",
      "Epoch [440/1000], loss is 0.120319\n",
      "Epoch [441/1000], loss is 0.111373\n",
      "Epoch [442/1000], loss is 0.145175\n",
      "Epoch [443/1000], loss is 0.084030\n",
      "Epoch [444/1000], loss is 0.094353\n",
      "Epoch [445/1000], loss is 0.068678\n",
      "Epoch [446/1000], loss is 0.091190\n",
      "Epoch [447/1000], loss is 0.101899\n",
      "Epoch [448/1000], loss is 0.129758\n",
      "Epoch [449/1000], loss is 0.113985\n",
      "Epoch [450/1000], loss is 0.070305\n",
      "Epoch [451/1000], loss is 0.090240\n",
      "Epoch [452/1000], loss is 0.052822\n",
      "Epoch [453/1000], loss is 0.079325\n",
      "Epoch [454/1000], loss is 0.081696\n",
      "Epoch [455/1000], loss is 0.131301\n",
      "Epoch [456/1000], loss is 0.078529\n",
      "Epoch [457/1000], loss is 0.093407\n",
      "Epoch [458/1000], loss is 0.121570\n",
      "Epoch [459/1000], loss is 0.088395\n",
      "Epoch [460/1000], loss is 0.083641\n",
      "Epoch [461/1000], loss is 0.121768\n",
      "Epoch [462/1000], loss is 0.093317\n",
      "Epoch [463/1000], loss is 0.078161\n",
      "Epoch [464/1000], loss is 0.066775\n",
      "Epoch [465/1000], loss is 0.064357\n",
      "Epoch [466/1000], loss is 0.086572\n",
      "Epoch [467/1000], loss is 0.113271\n",
      "Epoch [468/1000], loss is 0.106835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [469/1000], loss is 0.062361\n",
      "Epoch [470/1000], loss is 0.106506\n",
      "Epoch [471/1000], loss is 0.082008\n",
      "Epoch [472/1000], loss is 0.081699\n",
      "Epoch [473/1000], loss is 0.080612\n",
      "Epoch [474/1000], loss is 0.067685\n",
      "Epoch [475/1000], loss is 0.102461\n",
      "Epoch [476/1000], loss is 0.066415\n",
      "Epoch [477/1000], loss is 0.071387\n",
      "Epoch [478/1000], loss is 0.063666\n",
      "Epoch [479/1000], loss is 0.059320\n",
      "Epoch [480/1000], loss is 0.076988\n",
      "Epoch [481/1000], loss is 0.064498\n",
      "Epoch [482/1000], loss is 0.071336\n",
      "Epoch [483/1000], loss is 0.076633\n",
      "Epoch [484/1000], loss is 0.072159\n",
      "Epoch [485/1000], loss is 0.094227\n",
      "Epoch [486/1000], loss is 0.079218\n",
      "Epoch [487/1000], loss is 0.062626\n",
      "Epoch [488/1000], loss is 0.072352\n",
      "Epoch [489/1000], loss is 0.066883\n",
      "Epoch [490/1000], loss is 0.073188\n",
      "Epoch [491/1000], loss is 0.075444\n",
      "Epoch [492/1000], loss is 0.053299\n",
      "Epoch [493/1000], loss is 0.085390\n",
      "Epoch [494/1000], loss is 0.055746\n",
      "Epoch [495/1000], loss is 0.055252\n",
      "Epoch [496/1000], loss is 0.065712\n",
      "Epoch [497/1000], loss is 0.064956\n",
      "Epoch [498/1000], loss is 0.050369\n",
      "Epoch [499/1000], loss is 0.093737\n",
      "Epoch [500/1000], loss is 0.346469\n",
      "Epoch [501/1000], loss is 0.069831\n",
      "Epoch [502/1000], loss is 0.045766\n",
      "Epoch [503/1000], loss is 0.076632\n",
      "Epoch [504/1000], loss is 0.062038\n",
      "Epoch [505/1000], loss is 0.066713\n",
      "Epoch [506/1000], loss is 0.067306\n",
      "Epoch [507/1000], loss is 0.060829\n",
      "Epoch [508/1000], loss is 0.048554\n",
      "Epoch [509/1000], loss is 0.054729\n",
      "Epoch [510/1000], loss is 0.073483\n",
      "Epoch [511/1000], loss is 0.049802\n",
      "Epoch [512/1000], loss is 0.071198\n",
      "Epoch [513/1000], loss is 0.055433\n",
      "Epoch [514/1000], loss is 0.053963\n",
      "Epoch [515/1000], loss is 0.061856\n",
      "Epoch [516/1000], loss is 0.072070\n",
      "Epoch [517/1000], loss is 0.064101\n",
      "Epoch [518/1000], loss is 0.058539\n",
      "Epoch [519/1000], loss is 0.043495\n",
      "Epoch [520/1000], loss is 0.046301\n",
      "Epoch [521/1000], loss is 0.050280\n",
      "Epoch [522/1000], loss is 0.029201\n",
      "Epoch [523/1000], loss is 0.059371\n",
      "Epoch [524/1000], loss is 0.062407\n",
      "Epoch [525/1000], loss is 0.050680\n",
      "Epoch [526/1000], loss is 0.049314\n",
      "Epoch [527/1000], loss is 0.054897\n",
      "Epoch [528/1000], loss is 0.057819\n",
      "Epoch [529/1000], loss is 0.048334\n",
      "Epoch [530/1000], loss is 0.068240\n",
      "Epoch [531/1000], loss is 0.067902\n",
      "Epoch [532/1000], loss is 0.046320\n",
      "Epoch [533/1000], loss is 0.059317\n",
      "Epoch [534/1000], loss is 0.044228\n",
      "Epoch [535/1000], loss is 0.055161\n",
      "Epoch [536/1000], loss is 0.052388\n",
      "Epoch [537/1000], loss is 0.077556\n",
      "Epoch [538/1000], loss is 0.051084\n",
      "Epoch [539/1000], loss is 0.054967\n",
      "Epoch [540/1000], loss is 0.045361\n",
      "Epoch [541/1000], loss is 0.040927\n",
      "Epoch [542/1000], loss is 0.033302\n",
      "Epoch [543/1000], loss is 0.067407\n",
      "Epoch [544/1000], loss is 0.051524\n",
      "Epoch [545/1000], loss is 0.059439\n",
      "Epoch [546/1000], loss is 0.038346\n",
      "Epoch [547/1000], loss is 0.040371\n",
      "Epoch [548/1000], loss is 0.045633\n",
      "Epoch [549/1000], loss is 0.031288\n",
      "Epoch [550/1000], loss is 0.046381\n",
      "Epoch [551/1000], loss is 0.052419\n",
      "Epoch [552/1000], loss is 0.041710\n",
      "Epoch [553/1000], loss is 0.037417\n",
      "Epoch [554/1000], loss is 0.041319\n",
      "Epoch [555/1000], loss is 0.053346\n",
      "Epoch [556/1000], loss is 0.025223\n",
      "Epoch [557/1000], loss is 0.057731\n",
      "Epoch [558/1000], loss is 0.038471\n",
      "Epoch [559/1000], loss is 0.043467\n",
      "Epoch [560/1000], loss is 0.028615\n",
      "Epoch [561/1000], loss is 0.037230\n",
      "Epoch [562/1000], loss is 0.043406\n",
      "Epoch [563/1000], loss is 0.040985\n",
      "Epoch [564/1000], loss is 0.037589\n",
      "Epoch [565/1000], loss is 0.039806\n",
      "Epoch [566/1000], loss is 0.046862\n",
      "Epoch [567/1000], loss is 0.043106\n",
      "Epoch [568/1000], loss is 0.059312\n",
      "Epoch [569/1000], loss is 0.037168\n",
      "Epoch [570/1000], loss is 0.031711\n",
      "Epoch [571/1000], loss is 0.047097\n",
      "Epoch [572/1000], loss is 0.032231\n",
      "Epoch [573/1000], loss is 0.039824\n",
      "Epoch [574/1000], loss is 0.045682\n",
      "Epoch [575/1000], loss is 0.034143\n",
      "Epoch [576/1000], loss is 0.033638\n",
      "Epoch [577/1000], loss is 0.033664\n",
      "Epoch [578/1000], loss is 0.055464\n",
      "Epoch [579/1000], loss is 0.039946\n",
      "Epoch [580/1000], loss is 0.038888\n",
      "Epoch [581/1000], loss is 0.033611\n",
      "Epoch [582/1000], loss is 0.037060\n",
      "Epoch [583/1000], loss is 0.029207\n",
      "Epoch [584/1000], loss is 0.030387\n",
      "Epoch [585/1000], loss is 0.031088\n",
      "Epoch [586/1000], loss is 0.045106\n",
      "Epoch [587/1000], loss is 0.039946\n",
      "Epoch [588/1000], loss is 0.035894\n",
      "Epoch [589/1000], loss is 0.039784\n",
      "Epoch [590/1000], loss is 0.036444\n",
      "Epoch [591/1000], loss is 0.040895\n",
      "Epoch [592/1000], loss is 0.032176\n",
      "Epoch [593/1000], loss is 0.040274\n",
      "Epoch [594/1000], loss is 0.035247\n",
      "Epoch [595/1000], loss is 0.032333\n",
      "Epoch [596/1000], loss is 0.032626\n",
      "Epoch [597/1000], loss is 0.034379\n",
      "Epoch [598/1000], loss is 0.066045\n",
      "Epoch [599/1000], loss is 0.027314\n",
      "Epoch [600/1000], loss is 0.032580\n",
      "Epoch [601/1000], loss is 0.048779\n",
      "Epoch [602/1000], loss is 0.040694\n",
      "Epoch [603/1000], loss is 0.025716\n",
      "Epoch [604/1000], loss is 0.033726\n",
      "Epoch [605/1000], loss is 0.041773\n",
      "Epoch [606/1000], loss is 0.027999\n",
      "Epoch [607/1000], loss is 0.029471\n",
      "Epoch [608/1000], loss is 0.024821\n",
      "Epoch [609/1000], loss is 0.021508\n",
      "Epoch [610/1000], loss is 0.033948\n",
      "Epoch [611/1000], loss is 0.026636\n",
      "Epoch [612/1000], loss is 0.024845\n",
      "Epoch [613/1000], loss is 0.034039\n",
      "Epoch [614/1000], loss is 0.032444\n",
      "Epoch [615/1000], loss is 0.034616\n",
      "Epoch [616/1000], loss is 0.034305\n",
      "Epoch [617/1000], loss is 0.041983\n",
      "Epoch [618/1000], loss is 0.041204\n",
      "Epoch [619/1000], loss is 0.032730\n",
      "Epoch [620/1000], loss is 0.024099\n",
      "Epoch [621/1000], loss is 0.029598\n",
      "Epoch [622/1000], loss is 0.028673\n",
      "Epoch [623/1000], loss is 0.026816\n",
      "Epoch [624/1000], loss is 0.033043\n",
      "Epoch [625/1000], loss is 0.033606\n",
      "Epoch [626/1000], loss is 0.025205\n",
      "Epoch [627/1000], loss is 0.032455\n",
      "Epoch [628/1000], loss is 0.036439\n",
      "Epoch [629/1000], loss is 0.027421\n",
      "Epoch [630/1000], loss is 0.030034\n",
      "Epoch [631/1000], loss is 0.031753\n",
      "Epoch [632/1000], loss is 0.035221\n",
      "Epoch [633/1000], loss is 0.047742\n",
      "Epoch [634/1000], loss is 0.028970\n",
      "Epoch [635/1000], loss is 0.040149\n",
      "Epoch [636/1000], loss is 0.030232\n",
      "Epoch [637/1000], loss is 0.040601\n",
      "Epoch [638/1000], loss is 0.032085\n",
      "Epoch [639/1000], loss is 0.033696\n",
      "Epoch [640/1000], loss is 0.022037\n",
      "Epoch [641/1000], loss is 0.028671\n",
      "Epoch [642/1000], loss is 0.040480\n",
      "Epoch [643/1000], loss is 0.028663\n",
      "Epoch [644/1000], loss is 0.029694\n",
      "Epoch [645/1000], loss is 0.031600\n",
      "Epoch [646/1000], loss is 0.035705\n",
      "Epoch [647/1000], loss is 0.028806\n",
      "Epoch [648/1000], loss is 0.044463\n",
      "Epoch [649/1000], loss is 0.025744\n",
      "Epoch [650/1000], loss is 0.028927\n",
      "Epoch [651/1000], loss is 0.046879\n",
      "Epoch [652/1000], loss is 0.038804\n",
      "Epoch [653/1000], loss is 0.026479\n",
      "Epoch [654/1000], loss is 0.028564\n",
      "Epoch [655/1000], loss is 0.028642\n",
      "Epoch [656/1000], loss is 0.142481\n",
      "Epoch [657/1000], loss is 0.022269\n",
      "Epoch [658/1000], loss is 0.035278\n",
      "Epoch [659/1000], loss is 0.028298\n",
      "Epoch [660/1000], loss is 0.046860\n",
      "Epoch [661/1000], loss is 0.030233\n",
      "Epoch [662/1000], loss is 0.039635\n",
      "Epoch [663/1000], loss is 0.019581\n",
      "Epoch [664/1000], loss is 0.025633\n",
      "Epoch [665/1000], loss is 0.023249\n",
      "Epoch [666/1000], loss is 0.023653\n",
      "Epoch [667/1000], loss is 0.025933\n",
      "Epoch [668/1000], loss is 0.025789\n",
      "Epoch [669/1000], loss is 0.037193\n",
      "Epoch [670/1000], loss is 0.028016\n",
      "Epoch [671/1000], loss is 0.031058\n",
      "Epoch [672/1000], loss is 0.031889\n",
      "Epoch [673/1000], loss is 0.028729\n",
      "Epoch [674/1000], loss is 0.035877\n",
      "Epoch [675/1000], loss is 0.025045\n",
      "Epoch [676/1000], loss is 0.022538\n",
      "Epoch [677/1000], loss is 0.027138\n",
      "Epoch [678/1000], loss is 0.025082\n",
      "Epoch [679/1000], loss is 0.025379\n",
      "Epoch [680/1000], loss is 0.023667\n",
      "Epoch [681/1000], loss is 0.024489\n",
      "Epoch [682/1000], loss is 0.026259\n",
      "Epoch [683/1000], loss is 0.033099\n",
      "Epoch [684/1000], loss is 0.030564\n",
      "Epoch [685/1000], loss is 0.024029\n",
      "Epoch [686/1000], loss is 0.022810\n",
      "Epoch [687/1000], loss is 0.022309\n",
      "Epoch [688/1000], loss is 0.027827\n",
      "Epoch [689/1000], loss is 0.020305\n",
      "Epoch [690/1000], loss is 0.024440\n",
      "Epoch [691/1000], loss is 0.025852\n",
      "Epoch [692/1000], loss is 0.027484\n",
      "Epoch [693/1000], loss is 0.013380\n",
      "Epoch [694/1000], loss is 0.017871\n",
      "Epoch [695/1000], loss is 0.052387\n",
      "Epoch [696/1000], loss is 0.018463\n",
      "Epoch [697/1000], loss is 0.020858\n",
      "Epoch [698/1000], loss is 0.025605\n",
      "Epoch [699/1000], loss is 0.034501\n",
      "Epoch [700/1000], loss is 0.019475\n",
      "Epoch [701/1000], loss is 0.021625\n",
      "Epoch [702/1000], loss is 0.028285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [703/1000], loss is 0.019783\n",
      "Epoch [704/1000], loss is 0.019891\n",
      "Epoch [705/1000], loss is 0.026112\n",
      "Epoch [706/1000], loss is 0.030874\n",
      "Epoch [707/1000], loss is 0.028098\n",
      "Epoch [708/1000], loss is 0.019887\n",
      "Epoch [709/1000], loss is 0.028157\n",
      "Epoch [710/1000], loss is 0.025010\n",
      "Epoch [711/1000], loss is 0.020332\n",
      "Epoch [712/1000], loss is 0.025555\n",
      "Epoch [713/1000], loss is 0.018243\n",
      "Epoch [714/1000], loss is 0.025911\n",
      "Epoch [715/1000], loss is 0.023960\n",
      "Epoch [716/1000], loss is 0.024499\n",
      "Epoch [717/1000], loss is 0.019204\n",
      "Epoch [718/1000], loss is 0.032801\n",
      "Epoch [719/1000], loss is 0.019981\n",
      "Epoch [720/1000], loss is 0.019318\n",
      "Epoch [721/1000], loss is 0.029490\n",
      "Epoch [722/1000], loss is 0.019178\n",
      "Epoch [723/1000], loss is 0.027234\n",
      "Epoch [724/1000], loss is 0.019855\n",
      "Epoch [725/1000], loss is 0.026031\n",
      "Epoch [726/1000], loss is 0.020191\n",
      "Epoch [727/1000], loss is 0.019968\n",
      "Epoch [728/1000], loss is 0.032317\n",
      "Epoch [729/1000], loss is 0.020192\n",
      "Epoch [730/1000], loss is 0.015636\n",
      "Epoch [731/1000], loss is 0.020429\n",
      "Epoch [732/1000], loss is 0.023529\n",
      "Epoch [733/1000], loss is 0.022476\n",
      "Epoch [734/1000], loss is 0.023219\n",
      "Epoch [735/1000], loss is 0.030899\n",
      "Epoch [736/1000], loss is 0.027822\n",
      "Epoch [737/1000], loss is 0.025576\n",
      "Epoch [738/1000], loss is 0.027991\n",
      "Epoch [739/1000], loss is 0.021065\n",
      "Epoch [740/1000], loss is 0.021108\n",
      "Epoch [741/1000], loss is 0.021534\n",
      "Epoch [742/1000], loss is 0.021586\n",
      "Epoch [743/1000], loss is 0.021296\n",
      "Epoch [744/1000], loss is 0.021148\n",
      "Epoch [745/1000], loss is 0.016959\n",
      "Epoch [746/1000], loss is 0.021824\n",
      "Epoch [747/1000], loss is 0.025710\n",
      "Epoch [748/1000], loss is 0.016679\n",
      "Epoch [749/1000], loss is 0.023281\n",
      "Epoch [750/1000], loss is 0.025737\n",
      "Epoch [751/1000], loss is 0.022490\n",
      "Epoch [752/1000], loss is 0.018452\n",
      "Epoch [753/1000], loss is 0.021945\n",
      "Epoch [754/1000], loss is 0.018220\n",
      "Epoch [755/1000], loss is 0.018810\n",
      "Epoch [756/1000], loss is 0.016108\n",
      "Epoch [757/1000], loss is 0.014370\n",
      "Epoch [758/1000], loss is 0.018941\n",
      "Epoch [759/1000], loss is 0.018736\n",
      "Epoch [760/1000], loss is 0.020596\n",
      "Epoch [761/1000], loss is 0.020588\n",
      "Epoch [762/1000], loss is 0.019297\n",
      "Epoch [763/1000], loss is 0.024301\n",
      "Epoch [764/1000], loss is 0.018787\n",
      "Epoch [765/1000], loss is 0.022713\n",
      "Epoch [766/1000], loss is 0.018350\n",
      "Epoch [767/1000], loss is 0.021877\n",
      "Epoch [768/1000], loss is 0.017257\n",
      "Epoch [769/1000], loss is 0.024511\n",
      "Epoch [770/1000], loss is 0.018887\n",
      "Epoch [771/1000], loss is 0.019941\n",
      "Epoch [772/1000], loss is 0.018172\n",
      "Epoch [773/1000], loss is 0.017686\n",
      "Epoch [774/1000], loss is 0.015989\n",
      "Epoch [775/1000], loss is 0.016971\n",
      "Epoch [776/1000], loss is 0.037169\n",
      "Epoch [777/1000], loss is 0.034293\n",
      "Epoch [778/1000], loss is 0.019057\n",
      "Epoch [779/1000], loss is 0.025192\n",
      "Epoch [780/1000], loss is 0.014540\n",
      "Epoch [781/1000], loss is 0.016996\n",
      "Epoch [782/1000], loss is 0.017503\n",
      "Epoch [783/1000], loss is 0.027593\n",
      "Epoch [784/1000], loss is 0.017603\n",
      "Epoch [785/1000], loss is 0.020186\n",
      "Epoch [786/1000], loss is 0.017360\n",
      "Epoch [787/1000], loss is 0.018731\n",
      "Epoch [788/1000], loss is 0.042081\n",
      "Epoch [789/1000], loss is 0.024587\n",
      "Epoch [790/1000], loss is 0.017420\n",
      "Epoch [791/1000], loss is 0.016065\n",
      "Epoch [792/1000], loss is 0.019378\n",
      "Epoch [793/1000], loss is 0.016709\n",
      "Epoch [794/1000], loss is 0.016380\n",
      "Epoch [795/1000], loss is 0.024778\n",
      "Epoch [796/1000], loss is 0.023881\n",
      "Epoch [797/1000], loss is 0.020388\n",
      "Epoch [798/1000], loss is 0.020426\n",
      "Epoch [799/1000], loss is 0.020505\n",
      "Epoch [800/1000], loss is 0.016369\n",
      "Epoch [801/1000], loss is 0.014913\n",
      "Epoch [802/1000], loss is 0.015390\n",
      "Epoch [803/1000], loss is 0.022167\n",
      "Epoch [804/1000], loss is 0.018162\n",
      "Epoch [805/1000], loss is 0.021036\n",
      "Epoch [806/1000], loss is 0.019056\n",
      "Epoch [807/1000], loss is 0.020197\n",
      "Epoch [808/1000], loss is 0.015865\n",
      "Epoch [809/1000], loss is 0.017409\n",
      "Epoch [810/1000], loss is 0.013723\n",
      "Epoch [811/1000], loss is 0.013028\n",
      "Epoch [812/1000], loss is 0.021112\n",
      "Epoch [813/1000], loss is 0.016357\n",
      "Epoch [814/1000], loss is 0.014962\n",
      "Epoch [815/1000], loss is 0.014443\n",
      "Epoch [816/1000], loss is 0.022238\n",
      "Epoch [817/1000], loss is 0.015320\n",
      "Epoch [818/1000], loss is 0.015251\n",
      "Epoch [819/1000], loss is 0.011758\n",
      "Epoch [820/1000], loss is 0.017521\n",
      "Epoch [821/1000], loss is 0.020717\n",
      "Epoch [822/1000], loss is 0.016930\n",
      "Epoch [823/1000], loss is 0.029331\n",
      "Epoch [824/1000], loss is 0.015995\n",
      "Epoch [825/1000], loss is 0.016983\n",
      "Epoch [826/1000], loss is 0.023460\n",
      "Epoch [827/1000], loss is 0.019114\n",
      "Epoch [828/1000], loss is 0.013353\n",
      "Epoch [829/1000], loss is 0.015618\n",
      "Epoch [830/1000], loss is 0.016140\n",
      "Epoch [831/1000], loss is 0.019199\n",
      "Epoch [832/1000], loss is 0.018624\n",
      "Epoch [833/1000], loss is 0.014842\n",
      "Epoch [834/1000], loss is 0.016845\n",
      "Epoch [835/1000], loss is 0.020023\n",
      "Epoch [836/1000], loss is 0.014990\n",
      "Epoch [837/1000], loss is 0.019085\n",
      "Epoch [838/1000], loss is 0.013027\n",
      "Epoch [839/1000], loss is 0.012823\n",
      "Epoch [840/1000], loss is 0.016657\n",
      "Epoch [841/1000], loss is 0.015353\n",
      "Epoch [842/1000], loss is 0.012249\n",
      "Epoch [843/1000], loss is 0.034074\n",
      "Epoch [844/1000], loss is 0.030678\n",
      "Epoch [845/1000], loss is 0.017990\n",
      "Epoch [846/1000], loss is 0.014668\n",
      "Epoch [847/1000], loss is 0.014841\n",
      "Epoch [848/1000], loss is 0.016224\n",
      "Epoch [849/1000], loss is 0.018543\n",
      "Epoch [850/1000], loss is 0.015259\n",
      "Epoch [851/1000], loss is 0.014957\n",
      "Epoch [852/1000], loss is 0.014895\n",
      "Epoch [853/1000], loss is 0.017055\n",
      "Epoch [854/1000], loss is 0.013383\n",
      "Epoch [855/1000], loss is 0.014326\n",
      "Epoch [856/1000], loss is 0.028881\n",
      "Epoch [857/1000], loss is 0.018695\n",
      "Epoch [858/1000], loss is 0.015739\n",
      "Epoch [859/1000], loss is 0.012855\n",
      "Epoch [860/1000], loss is 0.037972\n",
      "Epoch [861/1000], loss is 0.017048\n",
      "Epoch [862/1000], loss is 0.018997\n",
      "Epoch [863/1000], loss is 0.015211\n",
      "Epoch [864/1000], loss is 0.014942\n",
      "Epoch [865/1000], loss is 0.010328\n",
      "Epoch [866/1000], loss is 0.032960\n",
      "Epoch [867/1000], loss is 0.016227\n",
      "Epoch [868/1000], loss is 0.015253\n",
      "Epoch [869/1000], loss is 0.032288\n",
      "Epoch [870/1000], loss is 0.017868\n",
      "Epoch [871/1000], loss is 0.017739\n",
      "Epoch [872/1000], loss is 0.015066\n",
      "Epoch [873/1000], loss is 0.016815\n",
      "Epoch [874/1000], loss is 0.014023\n",
      "Epoch [875/1000], loss is 0.015375\n",
      "Epoch [876/1000], loss is 0.017050\n",
      "Epoch [877/1000], loss is 0.024112\n",
      "Epoch [878/1000], loss is 0.018269\n",
      "Epoch [879/1000], loss is 0.015311\n",
      "Epoch [880/1000], loss is 0.007816\n",
      "Epoch [881/1000], loss is 0.016327\n",
      "Epoch [882/1000], loss is 0.015377\n",
      "Epoch [883/1000], loss is 0.014112\n",
      "Epoch [884/1000], loss is 0.012580\n",
      "Epoch [885/1000], loss is 0.015229\n",
      "Epoch [886/1000], loss is 0.011453\n",
      "Epoch [887/1000], loss is 0.015160\n",
      "Epoch [888/1000], loss is 0.012953\n",
      "Epoch [889/1000], loss is 0.012551\n",
      "Epoch [890/1000], loss is 0.014205\n",
      "Epoch [891/1000], loss is 0.019557\n",
      "Epoch [892/1000], loss is 0.012613\n",
      "Epoch [893/1000], loss is 0.016376\n",
      "Epoch [894/1000], loss is 0.013067\n",
      "Epoch [895/1000], loss is 0.019579\n",
      "Epoch [896/1000], loss is 0.012973\n",
      "Epoch [897/1000], loss is 0.013309\n",
      "Epoch [898/1000], loss is 0.046231\n",
      "Epoch [899/1000], loss is 0.018293\n",
      "Epoch [900/1000], loss is 0.013928\n",
      "Epoch [901/1000], loss is 0.015549\n",
      "Epoch [902/1000], loss is 0.011005\n",
      "Epoch [903/1000], loss is 0.012237\n",
      "Epoch [904/1000], loss is 0.027963\n",
      "Epoch [905/1000], loss is 0.008985\n",
      "Epoch [906/1000], loss is 0.016188\n",
      "Epoch [907/1000], loss is 0.014985\n",
      "Epoch [908/1000], loss is 0.019340\n",
      "Epoch [909/1000], loss is 0.014642\n",
      "Epoch [910/1000], loss is 0.018946\n",
      "Epoch [911/1000], loss is 0.017436\n",
      "Epoch [912/1000], loss is 0.014371\n",
      "Epoch [913/1000], loss is 0.014584\n",
      "Epoch [914/1000], loss is 0.012716\n",
      "Epoch [915/1000], loss is 0.028825\n",
      "Epoch [916/1000], loss is 0.013459\n",
      "Epoch [917/1000], loss is 0.016811\n",
      "Epoch [918/1000], loss is 0.012604\n",
      "Epoch [919/1000], loss is 0.011523\n",
      "Epoch [920/1000], loss is 0.013139\n",
      "Epoch [921/1000], loss is 0.015140\n",
      "Epoch [922/1000], loss is 0.011685\n",
      "Epoch [923/1000], loss is 0.015477\n",
      "Epoch [924/1000], loss is 0.015120\n",
      "Epoch [925/1000], loss is 0.014112\n",
      "Epoch [926/1000], loss is 0.014605\n",
      "Epoch [927/1000], loss is 0.011759\n",
      "Epoch [928/1000], loss is 0.010723\n",
      "Epoch [929/1000], loss is 0.013257\n",
      "Epoch [930/1000], loss is 0.012629\n",
      "Epoch [931/1000], loss is 0.020748\n",
      "Epoch [932/1000], loss is 0.010603\n",
      "Epoch [933/1000], loss is 0.013194\n",
      "Epoch [934/1000], loss is 0.028416\n",
      "Epoch [935/1000], loss is 0.021595\n",
      "Epoch [936/1000], loss is 0.013827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [937/1000], loss is 0.015503\n",
      "Epoch [938/1000], loss is 0.014611\n",
      "Epoch [939/1000], loss is 0.016966\n",
      "Epoch [940/1000], loss is 0.014794\n",
      "Epoch [941/1000], loss is 0.010461\n",
      "Epoch [942/1000], loss is 0.016052\n",
      "Epoch [943/1000], loss is 0.012073\n",
      "Epoch [944/1000], loss is 0.012925\n",
      "Epoch [945/1000], loss is 0.013264\n",
      "Epoch [946/1000], loss is 0.016711\n",
      "Epoch [947/1000], loss is 0.011192\n",
      "Epoch [948/1000], loss is 0.011081\n",
      "Epoch [949/1000], loss is 0.009707\n",
      "Epoch [950/1000], loss is 0.014360\n",
      "Epoch [951/1000], loss is 0.018376\n",
      "Epoch [952/1000], loss is 0.012923\n",
      "Epoch [953/1000], loss is 0.011620\n",
      "Epoch [954/1000], loss is 0.014544\n",
      "Epoch [955/1000], loss is 0.017397\n",
      "Epoch [956/1000], loss is 0.014591\n",
      "Epoch [957/1000], loss is 0.011933\n",
      "Epoch [958/1000], loss is 0.013439\n",
      "Epoch [959/1000], loss is 0.016259\n",
      "Epoch [960/1000], loss is 0.011760\n",
      "Epoch [961/1000], loss is 0.013333\n",
      "Epoch [962/1000], loss is 0.010855\n",
      "Epoch [963/1000], loss is 0.010191\n",
      "Epoch [964/1000], loss is 0.012641\n",
      "Epoch [965/1000], loss is 0.010097\n",
      "Epoch [966/1000], loss is 0.013006\n",
      "Epoch [967/1000], loss is 0.009605\n",
      "Epoch [968/1000], loss is 0.011780\n",
      "Epoch [969/1000], loss is 0.010265\n",
      "Epoch [970/1000], loss is 0.011432\n",
      "Epoch [971/1000], loss is 0.011110\n",
      "Epoch [972/1000], loss is 0.010913\n",
      "Epoch [973/1000], loss is 0.011757\n",
      "Epoch [974/1000], loss is 0.014598\n",
      "Epoch [975/1000], loss is 0.010348\n",
      "Epoch [976/1000], loss is 0.012576\n",
      "Epoch [977/1000], loss is 0.013522\n",
      "Epoch [978/1000], loss is 0.009890\n",
      "Epoch [979/1000], loss is 0.011252\n",
      "Epoch [980/1000], loss is 0.011033\n",
      "Epoch [981/1000], loss is 0.015095\n",
      "Epoch [982/1000], loss is 0.030698\n",
      "Epoch [983/1000], loss is 0.009395\n",
      "Epoch [984/1000], loss is 0.031671\n",
      "Epoch [985/1000], loss is 0.010872\n",
      "Epoch [986/1000], loss is 0.012165\n",
      "Epoch [987/1000], loss is 0.013214\n",
      "Epoch [988/1000], loss is 0.014809\n",
      "Epoch [989/1000], loss is 0.010939\n",
      "Epoch [990/1000], loss is 0.009547\n",
      "Epoch [991/1000], loss is 0.008872\n",
      "Epoch [992/1000], loss is 0.009213\n",
      "Epoch [993/1000], loss is 0.028429\n",
      "Epoch [994/1000], loss is 0.023257\n",
      "Epoch [995/1000], loss is 0.011394\n",
      "Epoch [996/1000], loss is 0.038106\n",
      "Epoch [997/1000], loss is 0.030948\n",
      "Epoch [998/1000], loss is 0.013721\n",
      "Epoch [999/1000], loss is 0.010219\n",
      "Epoch [1000/1000], loss is 0.010866\n"
     ]
    }
   ],
   "source": [
    "def make_features(x):\n",
    "    x = x.unsqueeze(1) # 将tensor大小从(n,)变成(n,1)\n",
    "    return torch.cat([x**i for i in range(1, 4)], 1)\n",
    "\n",
    "W_target = torch.FloatTensor([0.5, 3, 2.4]).unsqueeze(1)\n",
    "b_target = torch.FloatTensor([0.9])\n",
    "\n",
    "def f(x):\n",
    "    return x.mm(W_target) + b_target[0]\n",
    "\n",
    "# 随机生成一些数来得到每次的训练集\n",
    "def get_batch(batch_size=32):\n",
    "    random = torch.randn(batch_size)\n",
    "    x = make_features(random) # x大小为32*3\n",
    "    y = f(x) # y大小为32*1\n",
    "    if torch.cuda.is_available():\n",
    "        return Variable(x).cuda(), Variable(y).cuda()\n",
    "    else:\n",
    "        return Variable(x), Variable(y)\n",
    "    \n",
    "class poly_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(poly_model, self).__init__()\n",
    "        self.poly = nn.Linear(3, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.poly(x)\n",
    "        return out\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    model = poly_model().cuda()\n",
    "else:\n",
    "    model = poly_model()\n",
    "    \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epoch = 1000\n",
    "for i in range(num_epoch):\n",
    "    batch_x, batch_y = get_batch()\n",
    "    \n",
    "    out = model(batch_x)\n",
    "    loss = criterion(out, batch_y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch [{}/{}], loss is {:.6f}'.format(i+1, num_epoch, loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T03:37:03.251520Z",
     "start_time": "2019-09-05T03:37:03.015991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x715f7a20>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_x, batch_y = get_batch()\n",
    "\n",
    "model.eval()\n",
    "predict = model(batch_x)\n",
    "predict = predict.data.cpu().numpy()\n",
    "plt.plot(batch_x.cpu().numpy()[:,0], batch_y.cpu().numpy(), 'bo')\n",
    "plt.plot(batch_x.cpu().numpy()[:,0], predict, 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T06:01:12.991398Z",
     "start_time": "2019-09-05T06:01:12.983897Z"
    }
   },
   "source": [
    "### Logistic回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:27:55.381660Z",
     "start_time": "2019-09-05T08:27:55.378159Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:58:34.618213Z",
     "start_time": "2019-09-05T08:58:34.610212Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据类型\n",
    "with open('data.txt') as f:\n",
    "    data_list = f.readlines()\n",
    "    data_list = [i.split('\\n')[0] for i in data_list]\n",
    "    data_list = [i.split(',') for i in data_list]\n",
    "    data_list = [[float(i[0]), float(i[1]), float(i[2])] for i in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:58:35.801863Z",
     "start_time": "2019-09-05T08:58:35.792862Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data_list, columns=['x', 'y', 'label'])\n",
    "data0 = data[data.label == 0]\n",
    "data1 = data[data.label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:58:36.520955Z",
     "start_time": "2019-09-05T08:58:36.291925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x77836320>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data0.x, data0.y, 'ro', label='label 0')\n",
    "plt.plot(data1.x, data1.y, 'bo', label='label 1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:58:36.990014Z",
     "start_time": "2019-09-05T08:58:36.981013Z"
    }
   },
   "outputs": [],
   "source": [
    "x_data = torch.from_numpy(data[['x', 'y']].values).type(torch.FloatTensor)\n",
    "y_data = torch.from_numpy(data[['label']].values).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:58:37.775614Z",
     "start_time": "2019-09-05T08:58:37.759112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_data: torch.Size([100, 2])\n",
      "shape pf y_data: torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "print('shape of x_data:', x_data.size())\n",
    "print('shape pf y_data:', y_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:59:28.790092Z",
     "start_time": "2019-09-05T08:58:38.447699Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "epoch 1000\n",
      "loss is 0.5994\n",
      "acc is 0.6000\n",
      "********************\n",
      "epoch 2000\n",
      "loss is 0.5594\n",
      "acc is 0.6500\n",
      "********************\n",
      "epoch 3000\n",
      "loss is 0.5256\n",
      "acc is 0.6600\n",
      "********************\n",
      "epoch 4000\n",
      "loss is 0.4970\n",
      "acc is 0.7500\n",
      "********************\n",
      "epoch 5000\n",
      "loss is 0.4725\n",
      "acc is 0.7700\n",
      "********************\n",
      "epoch 6000\n",
      "loss is 0.4515\n",
      "acc is 0.8300\n",
      "********************\n",
      "epoch 7000\n",
      "loss is 0.4333\n",
      "acc is 0.8500\n",
      "********************\n",
      "epoch 8000\n",
      "loss is 0.4174\n",
      "acc is 0.8700\n",
      "********************\n",
      "epoch 9000\n",
      "loss is 0.4035\n",
      "acc is 0.8900\n",
      "********************\n",
      "epoch 10000\n",
      "loss is 0.3912\n",
      "acc is 0.9000\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.lr = nn.Linear(2, 1)\n",
    "        self.sm = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lr(x)\n",
    "        out = self.sm(x)\n",
    "        return out\n",
    "    \n",
    "lg_model = LogisticRegression()\n",
    "if torch.cuda.is_available():\n",
    "    lg_model.cuda()\n",
    "    \n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(lg_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    if torch.cuda.is_available():\n",
    "        x = Variable(x_data).cuda()\n",
    "        y = Variable(y_data).cuda()\n",
    "    else:\n",
    "        x = Variable(x_data)\n",
    "        y = Variable(y_data)\n",
    "        \n",
    "    out = lg_model(x)\n",
    "    loss = criterion(out, y)\n",
    "    print_loss = loss.data.item()\n",
    "    mask = out.ge(0.5).float()\n",
    "    correct = (mask == y).sum()\n",
    "    acc = correct.data.item() / x.size()[0]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print('*' * 20)\n",
    "        print('epoch {}'.format(epoch+1))\n",
    "        print('loss is {:.4f}'.format(print_loss))\n",
    "        print('acc is {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T08:56:30.656972Z",
     "start_time": "2019-09-05T08:56:30.430943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7891b4e0>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w0, w1 = lg_model.lr.weight[0]\n",
    "w0 = w0.data.item()\n",
    "w1 = w1.data.item()\n",
    "b = lg_model.lr.bias.item()\n",
    "\n",
    "plot_x = np.arange(30, 100, 0.1)\n",
    "plot_y = (-w0 * plot_x - b) / w1\n",
    "plt.plot(plot_x, plot_y)\n",
    "plt.plot(data0.x, data0.y, 'ro', label='label 0')\n",
    "plt.plot(data1.x, data1.y, 'bo', label='label 1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T09:04:06.626373Z",
     "start_time": "2019-09-05T09:04:06.616871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_model.lr.weight.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-05T09:04:14.918926Z",
     "start_time": "2019-09-05T09:04:14.911425Z"
    }
   },
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T07:14:10.884561Z",
     "start_time": "2019-09-06T07:14:10.874060Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden_1)\n",
    "        self.layer2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.layer3 = nn.Linear(n_hidden_2, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T07:24:14.899761Z",
     "start_time": "2019-09-06T07:24:14.891260Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActivationNet(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(ActivationNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Linear(in_dim, n_hidden_1),\n",
    "                        nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.Linear(n_hidden_1, n_hidden_2),\n",
    "                        nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T07:14:14.817061Z",
     "start_time": "2019-09-06T07:14:14.804059Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchNet(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(BatchNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Linear(in_dim, n_hidden_1),\n",
    "                        nn.BatchNorm1d(n_hidden_1),\n",
    "                        nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.Linear(n_hidden_1, n_hidden_2),\n",
    "                        nn.BatchNorm1d(n_hidden_2),\n",
    "                        nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T06:26:47.183457Z",
     "start_time": "2019-09-06T06:26:47.177956Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T08:35:21.159007Z",
     "start_time": "2019-09-06T08:27:19.110295Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20], loss: 0.275592\n",
      "Epoch [1/20], loss: 0.175772\n",
      "Epoch [2/20], loss: 0.115321\n",
      "Epoch [3/20], loss: 0.055003\n",
      "Epoch [4/20], loss: 0.087683\n",
      "Epoch [5/20], loss: 0.115100\n",
      "Epoch [6/20], loss: 0.056059\n",
      "Epoch [7/20], loss: 0.035070\n",
      "Epoch [8/20], loss: 0.094161\n",
      "Epoch [9/20], loss: 0.054084\n",
      "Epoch [10/20], loss: 0.031510\n",
      "Epoch [11/20], loss: 0.024199\n",
      "Epoch [12/20], loss: 0.012185\n",
      "Epoch [13/20], loss: 0.005978\n",
      "Epoch [14/20], loss: 0.011481\n",
      "Epoch [15/20], loss: 0.007811\n",
      "Epoch [16/20], loss: 0.031229\n",
      "Epoch [17/20], loss: 0.015977\n",
      "Epoch [18/20], loss: 0.037560\n",
      "Epoch [19/20], loss: 0.026304\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 20\n",
    "\n",
    "data_tf = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize([0.5], [0.5])]) # 减去0.5再除以0.5\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=data_tf, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=data_tf)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = BatchNet(28 * 28, 300, 100, 10)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    train_loss = 0.0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        # shape of batch_x: [64, 1, 28, 28]\n",
    "        # shape of batch_y: [64]\n",
    "        if torch.cuda.is_available():\n",
    "            batch_x = Variable(batch_x.view(-1, 28*28)).cuda()\n",
    "            batch_y = Variable(batch_y).cuda()\n",
    "        else:\n",
    "            batch_x = Variable(batch_x.view(-1, 28*28))\n",
    "            batch_y = Variable(batch_y)\n",
    "        \n",
    "        out = model(batch_x)\n",
    "        loss = criterion(out, batch_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = loss.data.item()\n",
    "    print('Epoch [{}/{}], loss: {:.6f}'.format(epoch, num_epoches, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T08:35:42.604231Z",
     "start_time": "2019-09-06T08:35:39.882385Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n",
      "d:\\python36\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.057900, Acc: 0.982600\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_loss = 0.0\n",
    "eval_acc = 0.0\n",
    "for data in test_loader:\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    if torch.cuda.is_available():\n",
    "        img = Variable(img, volatile=True).cuda()\n",
    "        label = Variable(label, volatile=True).cuda()\n",
    "    else:\n",
    "        img = Variable(img, volatile=True)\n",
    "        label = Variable(label, volatile=True)\n",
    "    \n",
    "    out = model(img)\n",
    "    loss = criterion(out, label)\n",
    "    eval_loss += loss.data.item() * label.size(0)\n",
    "    _, pred = torch.max(out, 1)\n",
    "    num_corrent = (pred == label).sum()\n",
    "    eval_acc += num_corrent.item()\n",
    "    \n",
    "print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / len(test_dataset), eval_acc / len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T06:57:39.307647Z",
     "start_time": "2019-09-06T06:57:39.299646Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets.MNIST?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
