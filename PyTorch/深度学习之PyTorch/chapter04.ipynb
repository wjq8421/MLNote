{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T09:47:22.386614Z",
     "start_time": "2019-09-11T09:47:22.382614Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T09:42:56.685559Z",
     "start_time": "2019-09-10T09:42:56.670558Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__() # b, 3, 32, 32\n",
    "        # 将卷积层、激活层、池化层组合在一起构成一个层结构\n",
    "        layer1 = nn.Sequential()\n",
    "        layer1.add_module('conv1', nn.Conv2d(3, 32, 3, 1, padding=1)) # b, 32, 32, 32\n",
    "        layer1.add_module('relu1', nn.ReLU(True))\n",
    "        layer1.add_module('pool1', nn.MaxPool2d(2, 2)) # b, 32, 16, 16\n",
    "        self.layer1 = layer1\n",
    "        \n",
    "        layer2 = nn.Sequential()\n",
    "        layer2.add_module('conv2', nn.Conv2d(32, 64, 3, 1, padding=1)) # b, 64, 16, 16\n",
    "        layer2.add_module('relu2', nn.ReLU(True))\n",
    "        layer2.add_module('pool2', nn.MaxPool2d(2, 2)) # b, 64, 8, 8\n",
    "        self.layer2 = layer2\n",
    "        \n",
    "        layer3 = nn.Sequential() \n",
    "        layer3.add_module('conv3', nn.Conv2d(64, 128, 3, 1, padding=1)) # b, 128, 8, 8\n",
    "        layer3.add_module('relu3', nn.ReLU(True))\n",
    "        layer3.add_module('pool3', nn.MaxPool2d(2, 2)) # b, 128, 4, 4\n",
    "        self.layer3 = layer3\n",
    "        \n",
    "        layer4 = nn.Sequential()\n",
    "        layer4.add_module('fc1', nn.Linear(2048, 512))\n",
    "        layer4.add_module('fc_relu1', nn.ReLU(True))\n",
    "        layer4.add_module('fc2', nn.Linear(512, 64))\n",
    "        layer4.add_module('fc_relu2', nn.ReLU(True))\n",
    "        layer4.add_module('fc3', nn.Linear(64, 10))\n",
    "        self.layer4 = layer4\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.layer1(x)\n",
    "        conv2 = self.layer2(conv1)\n",
    "        conv3 = self.layer3(conv2)\n",
    "        fc_input = conv3.view(conv3.size(0), -1)\n",
    "        fc_out = self.layer4(fc_input)\n",
    "        return fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T09:42:59.261707Z",
     "start_time": "2019-09-10T09:42:59.240705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (layer1): Sequential(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu3): ReLU(inplace=True)\n",
      "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (fc_relu1): ReLU(inplace=True)\n",
      "    (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "    (fc_relu2): ReLU(inplace=True)\n",
      "    (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T08:20:32.980796Z",
     "start_time": "2019-09-10T08:20:32.963795Z"
    }
   },
   "source": [
    "- 如何提取网络中指定的层结构、参数，以及如何对参数进行自定义的初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T08:32:18.695160Z",
     "start_time": "2019-09-10T08:32:18.685160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = nn.Sequential(*list(model.children())[:2])\n",
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T08:41:55.840171Z",
     "start_time": "2019-09-10T08:41:55.823170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "******************************\n",
      "Sequential(\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "******************************\n",
      "Sequential(\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "******************************\n",
      "Sequential(\n",
      "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (fc_relu1): ReLU(inplace=True)\n",
      "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (fc_relu2): ReLU(inplace=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for layer in model.children():\n",
    "    print(layer)\n",
    "    print('*'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T08:47:30.132291Z",
     "start_time": "2019-09-10T08:47:30.102290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.conv1.weight\n",
      "layer1.conv1.bias\n",
      "layer2.conv2.weight\n",
      "layer2.conv2.bias\n",
      "layer3.conv3.weight\n",
      "layer3.conv3.bias\n",
      "layer4.fc1.weight\n",
      "layer4.fc1.bias\n",
      "layer4.fc2.weight\n",
      "layer4.fc2.bias\n",
      "layer4.fc3.weight\n",
      "layer4.fc3.bias\n"
     ]
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T08:55:05.769352Z",
     "start_time": "2019-09-10T08:55:05.696348Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "d:\\python36\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  after removing the cwd from sys.path.\n",
      "d:\\python36\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.normal(m.weight.data)\n",
    "        nn.init.xavier_normal(m.weight.data)\n",
    "        nn.init.kaiming_normal(m.weight.data)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        m.weight.data.normal_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T02:13:44.086816Z",
     "start_time": "2019-09-11T02:13:44.073816Z"
    }
   },
   "outputs": [],
   "source": [
    "class Lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet, self).__init__()\n",
    "        layer1 = nn.Sequential() # b, 1, 32, 32\n",
    "        layer1.add_module('conv1', nn.Conv2d(1, 6, 5, 1)) # b, 6, 28, 28\n",
    "        # layer1.add_module('relu1', nn.ReLU())\n",
    "        layer1.add_module('pool1', nn.MaxPool2d(2, 2)) # b, 6, 14, 14\n",
    "        self.layer1 = layer1\n",
    "        \n",
    "        layer2 = nn.Sequential()\n",
    "        layer2.add_module('conv2', nn.Conv2d(6, 16, 5, 1)) # b, 16, 10, 10\n",
    "        # layer2.add_module('relu2', nn.ReLU())\n",
    "        layer2.add_module('pool2', nn.MaxPool2d(2, 2)) # b, 16, 5, 5\n",
    "        self.layer2 = layer2\n",
    "        \n",
    "        layer3 = nn.Sequential()\n",
    "        layer3.add_module('fc1', nn.Linear(400, 120))\n",
    "        # layer3.add_module('fc_relu1', nn.ReLU())\n",
    "        layer3.add_module('fc2', nn.Linear(120, 84))\n",
    "        # layer3.add_module('fc_relu2', nn.ReLU())\n",
    "        layer3.add_model('fc3', nn.Linear(84, 10))\n",
    "        self.layer3 = layer3\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.layer1(x)\n",
    "        conv2 = self.layer2(conv1)\n",
    "        finput = conv2.view(conv2.size(0), -1)\n",
    "        out = self.layer3(finput)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T08:56:56.702555Z",
     "start_time": "2019-09-11T08:56:56.691554Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "    \n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, pool_features):\n",
    "        super(Inception, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "        \n",
    "        self.branch5x5_1 = BasicConv2d(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = BasicConv2d(48, 64, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.branch3x3db_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3db_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3db_3 = BasicConv2d(96, 96, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.branch_pool = BasicConv2d(in_channels, pool_features, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        \n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "        \n",
    "        branch3x3db1 = self.branch3x3db_1(x)\n",
    "        branch3x3db1 = self.branch3x3db_2(branch3x3db1)\n",
    "        branch3x3db1 = self.branch3x3db_3(branch3x3db1)\n",
    "        \n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        \n",
    "        outputs = [branch1x1, branch5x5, branch3x3db1, branch_pool]\n",
    "        return torch.cat(outputs, 1) # 按深度拼接起来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T09:08:28.086100Z",
     "start_time": "2019-09-11T09:08:28.076099Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "        \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T09:48:27.967365Z",
     "start_time": "2019-09-11T09:48:27.951364Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        layer1 = nn.Sequential() # b, 1, 32, 32\n",
    "        layer1.add_module('conv1', nn.Conv2d(1, 16, kernel_size=3)) # b, 16, 26, 26\n",
    "        layer1.add_module('bn1', nn.BatchNorm2d(16))\n",
    "        layer1.add_module('relu1', nn.ReLU(inplace=True))\n",
    "        self.layer1 = layer1\n",
    "        \n",
    "        layer2 = nn.Sequential()\n",
    "        layer2.add_module('conv2', nn.Conv2d(16, 32, kernel_size=3)) # n, 32, 24, 24\n",
    "        layer2.add_module('bn2', nn.BatchNorm2d(32))\n",
    "        layer2.add_module('relu2', nn.ReLU(inplace=True))\n",
    "        layer2.add_module('pool2', nn.MaxPool2d(kernel_size=2, stride=2)) # n, 32, 12, 12\n",
    "        self.layer2 = layer2\n",
    "        \n",
    "        layer3 = nn.Sequential() \n",
    "        layer3.add_module('conv3', nn.Conv2d(32, 64, kernel_size=3)) # b, 64, 10, 10\n",
    "        layer3.add_module('bn3', nn.BatchNorm2d(64))\n",
    "        layer3.add_module('relu3', nn.ReLU(inplace=True)) \n",
    "        self.layer3 = layer3\n",
    "        \n",
    "        layer4 = nn.Sequential()\n",
    "        layer4.add_module('conv4', nn.Conv2d(64, 128, kernel_size=3)) # n, 128, 8, 8\n",
    "        layer4.add_module('bn4', nn.BatchNorm2d(128))\n",
    "        layer4.add_module('relu4', nn.ReLU(inplace=True))\n",
    "        layer4.add_module('pool4', nn.MaxPool2d(kernel_size=2, stride=2)) # n, 128, 4, 4\n",
    "        self.layer4 = layer4\n",
    "        \n",
    "        fc = nn.Sequential()\n",
    "        fc.add_module('fc1', nn.Linear(128*4*4, 1024))\n",
    "        fc.add_module('fc_relu1', nn.ReLU(inplace=True))\n",
    "        fc.add_module('fc2', nn.Linear(1024, 128))\n",
    "        fc.add_module('fc_relu2', nn.ReLU(inplace=True))\n",
    "        fc.add_module('fc3', nn.Linear(128, 10))\n",
    "        self.fc = fc\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T10:04:47.107369Z",
     "start_time": "2019-09-11T09:48:30.989538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20], loss: 0.026402\n",
      "Epoch [1/20], loss: 0.127695\n",
      "Epoch [2/20], loss: 0.051676\n",
      "Epoch [3/20], loss: 0.002557\n",
      "Epoch [4/20], loss: 0.012357\n",
      "Epoch [5/20], loss: 0.001415\n",
      "Epoch [6/20], loss: 0.002970\n",
      "Epoch [7/20], loss: 0.006304\n",
      "Epoch [8/20], loss: 0.010297\n",
      "Epoch [9/20], loss: 0.100375\n",
      "Epoch [10/20], loss: 0.030284\n",
      "Epoch [11/20], loss: 0.188129\n",
      "Epoch [12/20], loss: 0.009271\n",
      "Epoch [13/20], loss: 0.001434\n",
      "Epoch [14/20], loss: 0.018635\n",
      "Epoch [15/20], loss: 0.006563\n",
      "Epoch [16/20], loss: 0.003946\n",
      "Epoch [17/20], loss: 0.000297\n",
      "Epoch [18/20], loss: 0.002437\n",
      "Epoch [19/20], loss: 0.002046\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 20\n",
    "\n",
    "data_tf = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize([0.5], [0.5])]) # 减去0.5再除以0.5\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=data_tf, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=data_tf)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = CNN()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    train_loss = 0.0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        # shape of batch_x: [64, 1, 28, 28]\n",
    "        # shape of batch_y: [64]\n",
    "        if torch.cuda.is_available():\n",
    "            batch_x = Variable(batch_x).cuda()\n",
    "            batch_y = Variable(batch_y).cuda()\n",
    "        else:\n",
    "            batch_x = Variable(batch_x)\n",
    "            batch_y = Variable(batch_y)\n",
    "        \n",
    "        out = model(batch_x)\n",
    "        loss = criterion(out, batch_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss = loss.data.item()\n",
    "    print('Epoch [{}/{}], loss: {:.6f}'.format(epoch, num_epoches, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T09:40:13.226210Z",
     "start_time": "2019-09-10T09:40:13.217209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16 * 5 * 5 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
